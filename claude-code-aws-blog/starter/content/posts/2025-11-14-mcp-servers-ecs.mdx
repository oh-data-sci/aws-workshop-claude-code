---
title: "Deploying MCP Servers on AWS ECS: A Complete Infrastructure Guide"
date: "2025-11-14"
author: "AWS Developer"
excerpt: "Learn how to deploy Model Context Protocol (MCP) servers on AWS ECS with best practices for scalability, security, and cost optimization."
category: "Infrastructure"
tags: ["AWS", "Claude Code", "ECS", "MCP", "Containers", "Docker", "Infrastructure", "Fargate"]
published: true
---

## Introduction

Model Context Protocol (MCP) servers enable Claude Code and other AI applications to access external data sources, tools, and services through a standardized interface. When building production AI systems, deploying MCP servers on AWS Elastic Container Service (ECS) provides a scalable, managed solution that integrates seamlessly with the broader AWS ecosystem.

In this comprehensive guide, you'll learn:
- How to containerize MCP servers for ECS deployment
- Setting up ECS clusters with Fargate for serverless container management
- Implementing networking, security, and monitoring best practices
- Scaling strategies and cost optimization techniques

This matters for AWS developers because MCP servers act as the bridge between your AI applications and enterprise data sources—and running them on ECS ensures reliability, scalability, and operational excellence without the overhead of managing Kubernetes or EC2 instances directly.

## Prerequisites

Before deploying MCP servers on ECS, ensure you have:

### AWS Resources
- An active AWS account with appropriate permissions
- AWS CLI v2.x or higher installed and configured
- An existing VPC with public and private subnets (or willingness to create one)
- IAM permissions for ECS, ECR, CloudWatch, and related services

### Tools and Dependencies
- Docker installed locally for building container images
- AWS CDK or Terraform (optional, for infrastructure as code)
- An MCP server implementation (Node.js, Python, or other)
- Basic understanding of container networking

### Prior Knowledge
- Familiarity with Docker and containerization concepts
- Understanding of AWS VPC networking (subnets, security groups, NAT gateways)
- Basic knowledge of ECS concepts (tasks, services, clusters)
- Experience with environment variables and secrets management

## Step-by-Step Guide

### Step 1: Containerize Your MCP Server

First, create a Dockerfile for your MCP server. Here's an example for a Node.js-based MCP server:

```dockerfile
# Dockerfile
FROM node:20-alpine

# Set working directory
WORKDIR /app

# Copy package files
COPY package*.json ./

# Install production dependencies
RUN npm ci --only=production

# Copy application code
COPY . .

# Create non-root user for security
RUN addgroup -g 1001 -S nodejs && \
    adduser -S nodejs -u 1001 && \
    chown -R nodejs:nodejs /app

# Switch to non-root user
USER nodejs

# Expose MCP server port
EXPOSE 3000

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD node healthcheck.js || exit 1

# Start the MCP server
CMD ["node", "server.js"]
```

Create a simple health check script:

```javascript
// healthcheck.js
const http = require('http');

const options = {
  host: 'localhost',
  port: 3000,
  path: '/health',
  timeout: 2000
};

const healthCheck = http.request(options, (res) => {
  console.log(`Health check status: ${res.statusCode}`);
  if (res.statusCode === 200) {
    process.exit(0);
  } else {
    process.exit(1);
  }
});

healthCheck.on('error', (err) => {
  console.error('Health check failed:', err);
  process.exit(1);
});

healthCheck.end();
```

Build and test your container locally:

```bash
# Build the Docker image
docker build -t mcp-server:latest .

# Run locally to test
docker run -p 3000:3000 \
  -e MCP_CONFIG_PATH=/app/config.json \
  mcp-server:latest

# Test the health endpoint
curl http://localhost:3000/health
```

### Step 2: Push Container to Amazon ECR

Create an ECR repository and push your container:

```bash
# Set variables
AWS_REGION=us-east-1
ECR_REPO_NAME=mcp-server
AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)

# Create ECR repository
aws ecr create-repository \
  --repository-name ${ECR_REPO_NAME} \
  --region ${AWS_REGION} \
  --image-scanning-configuration scanOnPush=true \
  --encryption-configuration encryptionType=AES256

# Authenticate Docker to ECR
aws ecr get-login-password --region ${AWS_REGION} | \
  docker login --username AWS --password-stdin \
  ${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com

# Tag your image
docker tag mcp-server:latest \
  ${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/${ECR_REPO_NAME}:latest

# Push to ECR
docker push ${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/${ECR_REPO_NAME}:latest
```

### Step 3: Create ECS Task Definition

Create a task definition JSON file:

```json
{
  "family": "mcp-server-task",
  "networkMode": "awsvpc",
  "requiresCompatibilities": ["FARGATE"],
  "cpu": "512",
  "memory": "1024",
  "executionRoleArn": "arn:aws:iam::ACCOUNT_ID:role/ecsTaskExecutionRole",
  "taskRoleArn": "arn:aws:iam::ACCOUNT_ID:role/mcpServerTaskRole",
  "containerDefinitions": [
    {
      "name": "mcp-server",
      "image": "ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com/mcp-server:latest",
      "portMappings": [
        {
          "containerPort": 3000,
          "protocol": "tcp"
        }
      ],
      "essential": true,
      "environment": [
        {
          "name": "NODE_ENV",
          "value": "production"
        },
        {
          "name": "MCP_PORT",
          "value": "3000"
        }
      ],
      "secrets": [
        {
          "name": "API_KEY",
          "valueFrom": "arn:aws:secretsmanager:us-east-1:ACCOUNT_ID:secret:mcp/api-key"
        }
      ],
      "logConfiguration": {
        "logDriver": "awslogs",
        "options": {
          "awslogs-group": "/ecs/mcp-server",
          "awslogs-region": "us-east-1",
          "awslogs-stream-prefix": "ecs"
        }
      },
      "healthCheck": {
        "command": ["CMD-SHELL", "node healthcheck.js || exit 1"],
        "interval": 30,
        "timeout": 5,
        "retries": 3,
        "startPeriod": 60
      }
    }
  ]
}
```

Register the task definition:

```bash
# Create CloudWatch log group first
aws logs create-log-group --log-group-name /ecs/mcp-server

# Register task definition
aws ecs register-task-definition \
  --cli-input-json file://task-definition.json
```

### Step 4: Create IAM Roles

Create the task execution role (for ECS to pull images and write logs):

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "ecr:GetAuthorizationToken",
        "ecr:BatchCheckLayerAvailability",
        "ecr:GetDownloadUrlForLayer",
        "ecr:BatchGetImage",
        "logs:CreateLogStream",
        "logs:PutLogEvents",
        "secretsmanager:GetSecretValue"
      ],
      "Resource": "*"
    }
  ]
}
```

Create the task role (for your MCP server application to access AWS services):

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:GetObject",
        "s3:ListBucket"
      ],
      "Resource": [
        "arn:aws:s3:::your-mcp-data-bucket",
        "arn:aws:s3:::your-mcp-data-bucket/*"
      ]
    },
    {
      "Effect": "Allow",
      "Action": [
        "dynamodb:GetItem",
        "dynamodb:Query",
        "dynamodb:Scan"
      ],
      "Resource": "arn:aws:dynamodb:*:*:table/mcp-*"
    }
  ]
}
```

### Step 5: Create ECS Cluster and Service

Create an ECS cluster with Fargate:

```bash
# Create ECS cluster
aws ecs create-cluster \
  --cluster-name mcp-cluster \
  --capacity-providers FARGATE FARGATE_SPOT \
  --default-capacity-provider-strategy \
    capacityProvider=FARGATE,weight=1,base=1 \
    capacityProvider=FARGATE_SPOT,weight=4

# Create security group for MCP server
VPC_ID=$(aws ec2 describe-vpcs --filters "Name=isDefault,Values=true" --query "Vpcs[0].VpcId" --output text)

SG_ID=$(aws ec2 create-security-group \
  --group-name mcp-server-sg \
  --description "Security group for MCP server" \
  --vpc-id ${VPC_ID} \
  --output text --query 'GroupId')

# Allow inbound traffic on port 3000 (adjust source as needed)
aws ec2 authorize-security-group-ingress \
  --group-id ${SG_ID} \
  --protocol tcp \
  --port 3000 \
  --cidr 10.0.0.0/16  # Adjust to your VPC CIDR

# Get subnet IDs (use private subnets for production)
SUBNET_IDS=$(aws ec2 describe-subnets \
  --filters "Name=vpc-id,Values=${VPC_ID}" \
  --query "Subnets[?MapPublicIpOnLaunch==\`false\`].SubnetId" \
  --output text | tr '\t' ',')
```

Create the ECS service:

```bash
aws ecs create-service \
  --cluster mcp-cluster \
  --service-name mcp-server-service \
  --task-definition mcp-server-task \
  --desired-count 2 \
  --launch-type FARGATE \
  --platform-version LATEST \
  --network-configuration "awsvpcConfiguration={
    subnets=[${SUBNET_IDS}],
    securityGroups=[${SG_ID}],
    assignPublicIp=DISABLED
  }" \
  --deployment-configuration "deploymentCircuitBreaker={enable=true,rollback=true}" \
  --enable-execute-command
```

### Step 6: Add Application Load Balancer (Optional)

For HTTP-based MCP servers, add an ALB:

```bash
# Create target group
TG_ARN=$(aws elbv2 create-target-group \
  --name mcp-server-tg \
  --protocol HTTP \
  --port 3000 \
  --vpc-id ${VPC_ID} \
  --target-type ip \
  --health-check-enabled \
  --health-check-path /health \
  --health-check-interval-seconds 30 \
  --health-check-timeout-seconds 5 \
  --healthy-threshold-count 2 \
  --unhealthy-threshold-count 3 \
  --query 'TargetGroups[0].TargetGroupArn' \
  --output text)

# Create ALB (simplified - adjust for production)
ALB_ARN=$(aws elbv2 create-load-balancer \
  --name mcp-server-alb \
  --subnets ${SUBNET_IDS} \
  --security-groups ${SG_ID} \
  --scheme internal \
  --type application \
  --query 'LoadBalancers[0].LoadBalancerArn' \
  --output text)

# Create listener
aws elbv2 create-listener \
  --load-balancer-arn ${ALB_ARN} \
  --protocol HTTP \
  --port 80 \
  --default-actions Type=forward,TargetGroupArn=${TG_ARN}

# Update ECS service to use load balancer
aws ecs update-service \
  --cluster mcp-cluster \
  --service mcp-server-service \
  --load-balancers "targetGroupArn=${TG_ARN},containerName=mcp-server,containerPort=3000"
```

## Best Practices

### 1. Use Fargate for Operational Simplicity

**Why**: Fargate eliminates the need to manage EC2 instances, automatically handles patching, and scales seamlessly.

**Implementation**:
- Use Fargate for most MCP server workloads
- Consider Fargate Spot for cost savings on non-critical workloads
- Use EC2 launch type only for specialized requirements (GPU, high memory, custom AMIs)

### 2. Implement Proper Secret Management

**Never** hardcode credentials or API keys:

```bash
# Store secrets in AWS Secrets Manager
aws secretsmanager create-secret \
  --name mcp/database-credentials \
  --secret-string '{
    "username": "admin",
    "password": "your-secure-password",
    "host": "db.example.com",
    "port": "5432"
  }'

# Reference in task definition
{
  "secrets": [
    {
      "name": "DB_CREDENTIALS",
      "valueFrom": "arn:aws:secretsmanager:region:account:secret:mcp/database-credentials"
    }
  ]
}
```

### 3. Configure Auto Scaling

Set up ECS service auto scaling based on metrics:

```bash
# Register scalable target
aws application-autoscaling register-scalable-target \
  --service-namespace ecs \
  --resource-id service/mcp-cluster/mcp-server-service \
  --scalable-dimension ecs:service:DesiredCount \
  --min-capacity 2 \
  --max-capacity 10

# Create scaling policy (CPU-based)
aws application-autoscaling put-scaling-policy \
  --service-namespace ecs \
  --resource-id service/mcp-cluster/mcp-server-service \
  --scalable-dimension ecs:service:DesiredCount \
  --policy-name mcp-cpu-scaling \
  --policy-type TargetTrackingScaling \
  --target-tracking-scaling-policy-configuration '{
    "TargetValue": 70.0,
    "PredefinedMetricSpecification": {
      "PredefinedMetricType": "ECSServiceAverageCPUUtilization"
    },
    "ScaleInCooldown": 300,
    "ScaleOutCooldown": 60
  }'
```

### 4. Enable Container Insights

Monitor your ECS services with CloudWatch Container Insights:

```bash
# Enable Container Insights on cluster
aws ecs update-cluster-settings \
  --cluster mcp-cluster \
  --settings name=containerInsights,value=enabled
```

This provides detailed metrics for:
- CPU and memory utilization
- Network traffic
- Task and service counts
- Container-level metrics

### 5. Implement Health Checks and Circuit Breakers

Enable deployment circuit breakers to automatically roll back failed deployments:

```json
{
  "deploymentConfiguration": {
    "deploymentCircuitBreaker": {
      "enable": true,
      "rollback": true
    },
    "maximumPercent": 200,
    "minimumHealthyPercent": 100
  }
}
```

### 6. Use Private Subnets with NAT Gateway

Deploy ECS tasks in private subnets for security:

```
[Internet] → [ALB in Public Subnet] → [ECS Tasks in Private Subnet] → [NAT Gateway] → [Internet]
```

Benefits:
- Tasks don't have public IP addresses
- Outbound internet access via NAT Gateway
- Better security posture
- Reduced attack surface

### 7. Optimize Container Images

Reduce deployment time and costs:

```dockerfile
# Use multi-stage builds
FROM node:20-alpine AS builder
WORKDIR /app
COPY package*.json ./
RUN npm ci
COPY . .
RUN npm run build

# Production stage
FROM node:20-alpine
WORKDIR /app
COPY --from=builder /app/dist ./dist
COPY --from=builder /app/node_modules ./node_modules
USER node
CMD ["node", "dist/server.js"]
```

Benefits:
- Smaller image sizes (faster pulls)
- Reduced storage costs in ECR
- Faster task startup times
- Better security (fewer packages)

## Common Pitfalls

### 1. Insufficient Task Resources

**Problem**: Tasks crash with out-of-memory errors or throttle due to CPU limits.

**Solution**:
- Start with conservative resource allocations (e.g., 512 CPU, 1024 MB memory)
- Monitor CloudWatch metrics for actual usage
- Adjust task definition based on real-world data
- Remember: Fargate CPU/memory combinations have specific allowed values

Valid Fargate combinations:
- 512 CPU: 1024-4096 MB (in 1024 MB increments)
- 1024 CPU: 2048-8192 MB (in 1024 MB increments)
- 2048 CPU: 4096-16384 MB (in 1024 MB increments)

### 2. Missing VPC Endpoints

**Problem**: Tasks in private subnets can't pull ECR images or write logs, causing deployment failures.

**Solution**: Create VPC endpoints for ECR and CloudWatch Logs:

```bash
# ECR endpoints
aws ec2 create-vpc-endpoint \
  --vpc-id ${VPC_ID} \
  --service-name com.amazonaws.${AWS_REGION}.ecr.dkr \
  --vpc-endpoint-type Interface

aws ec2 create-vpc-endpoint \
  --vpc-id ${VPC_ID} \
  --service-name com.amazonaws.${AWS_REGION}.ecr.api \
  --vpc-endpoint-type Interface

# S3 gateway endpoint (for ECR layers)
aws ec2 create-vpc-endpoint \
  --vpc-id ${VPC_ID} \
  --service-name com.amazonaws.${AWS_REGION}.s3 \
  --vpc-endpoint-type Gateway

# CloudWatch Logs endpoint
aws ec2 create-vpc-endpoint \
  --vpc-id ${VPC_ID} \
  --service-name com.amazonaws.${AWS_REGION}.logs \
  --vpc-endpoint-type Interface
```

### 3. Improper Security Group Configuration

**Problem**: Tasks can't communicate with dependencies (databases, APIs) or receive traffic.

**Solution**:
- Review security group rules carefully
- Allow outbound traffic to necessary services
- Use security group references instead of CIDR blocks where possible
- Test connectivity using ECS Exec

```bash
# Enable ECS Exec for debugging
aws ecs execute-command \
  --cluster mcp-cluster \
  --task TASK_ID \
  --container mcp-server \
  --interactive \
  --command "/bin/sh"
```

### 4. Not Using Task Roles vs Execution Roles

**Problem**: Confusion between task execution role and task role leads to permission errors.

**Key Difference**:
- **Execution Role**: Used by ECS agent to pull images, write logs, fetch secrets
- **Task Role**: Used by your application code to access AWS services

**Solution**: Always define both roles with appropriate permissions:
- Execution role: ECR, CloudWatch Logs, Secrets Manager access
- Task role: Application-specific permissions (S3, DynamoDB, etc.)

### 5. Ignoring Cost Optimization

**Problem**: Running expensive configurations 24/7 when not needed.

**Solutions**:
- Use Fargate Spot for dev/test environments (up to 70% cost savings)
- Implement scheduled scaling (scale down at night/weekends)
- Right-size task resources based on actual usage
- Use Savings Plans for predictable workloads
- Enable ECR lifecycle policies to clean up old images

Example lifecycle policy:

```json
{
  "rules": [
    {
      "rulePriority": 1,
      "description": "Keep last 10 images",
      "selection": {
        "tagStatus": "any",
        "countType": "imageCountMoreThan",
        "countNumber": 10
      },
      "action": {
        "type": "expire"
      }
    }
  ]
}
```

### 6. Lack of Observability

**Problem**: Can't diagnose issues when they occur in production.

**Solution**: Implement comprehensive logging and monitoring:

```javascript
// Add structured logging
const winston = require('winston');

const logger = winston.createLogger({
  level: 'info',
  format: winston.format.json(),
  defaultMeta: {
    service: 'mcp-server',
    environment: process.env.NODE_ENV
  },
  transports: [
    new winston.transports.Console()
  ]
});

// Log all MCP requests
app.use((req, res, next) => {
  logger.info('MCP request', {
    method: req.method,
    path: req.path,
    ip: req.ip
  });
  next();
});
```

Set up CloudWatch alarms:

```bash
# High CPU alarm
aws cloudwatch put-metric-alarm \
  --alarm-name mcp-server-high-cpu \
  --alarm-description "Alert when CPU exceeds 80%" \
  --metric-name CPUUtilization \
  --namespace AWS/ECS \
  --statistic Average \
  --period 300 \
  --threshold 80 \
  --comparison-operator GreaterThanThreshold \
  --evaluation-periods 2
```

## Conclusion

Deploying MCP servers on AWS ECS provides a robust, scalable infrastructure for production AI applications. By containerizing your MCP servers and leveraging ECS with Fargate, you gain operational simplicity while maintaining full control over networking, security, and resource allocation.

**Key Takeaways**:
- Containerization makes MCP servers portable and easy to deploy
- Fargate eliminates infrastructure management overhead
- Proper IAM roles and secret management are critical for security
- Auto scaling ensures your MCP servers can handle variable loads
- VPC endpoints and private subnets enhance security posture
- Comprehensive monitoring is essential for production operations

**What We Covered**:
- Containerizing MCP servers with Docker
- Setting up ECR for container image storage
- Creating ECS task definitions with proper configurations
- Deploying services with Fargate and optional load balancing
- Implementing security best practices with IAM and VPC
- Configuring auto scaling and monitoring
- Avoiding common pitfalls in ECS deployments

**Next Steps**:
1. Start with a simple MCP server and deploy it to ECS following this guide
2. Implement CI/CD pipelines for automated deployments (CodePipeline, GitHub Actions)
3. Explore ECS Service Connect for service mesh capabilities
4. Integrate with AWS App Mesh for advanced traffic management
5. Set up centralized logging with CloudWatch Logs Insights or OpenSearch
6. Implement blue/green deployments for zero-downtime updates
7. Consider AWS Copilot CLI for simplified ECS deployments

## Further Reading

### AWS Documentation
- [Amazon ECS Developer Guide](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/)
- [AWS Fargate Documentation](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/AWS_Fargate.html)
- [Amazon ECR User Guide](https://docs.aws.amazon.com/AmazonECR/latest/userguide/)
- [ECS Task Definitions](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definitions.html)
- [ECS Service Auto Scaling](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-auto-scaling.html)
- [AWS Copilot CLI](https://aws.github.io/copilot-cli/)

### Related Blog Posts
- AWS Bedrock Fundamentals: Building AI Applications at Scale
- Building Custom MCP Servers for AI Applications
- Getting Started with Claude Code and AWS
- CI/CD Pipelines for Containerized Applications

### Additional Resources
- [Model Context Protocol Specification](https://spec.modelcontextprotocol.io/)
- [ECS Samples GitHub Repository](https://github.com/aws-samples/amazon-ecs-samples)
- [AWS Containers Blog](https://aws.amazon.com/blogs/containers/)
- [Docker Best Practices](https://docs.docker.com/develop/dev-best-practices/)
- [ECS Workshop](https://ecsworkshop.com/)
- [AWS Well-Architected Framework](https://aws.amazon.com/architecture/well-architected/)
